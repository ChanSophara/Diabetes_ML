{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sopha\\AppData\\Local\\Temp\\ipykernel_4616\\1237712077.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the dataset\n",
    "data = pd.read_csv('diabetes_012.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012            0\n",
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "AnyHealthcare           0\n",
       "NoDocbcCost             0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Sex                     0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "data_np = data.values\n",
    "target_np = data_np[:, 0]  # Assuming 'Diabetes_binary' is the target variable\n",
    "features_np = data_np[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training+validation (80%) and testing (20%)\n",
    "features_train_val, features_test, target_train_val, target_test = train_test_split(\n",
    "    features_np, target_np, test_size=0.20, random_state=42)\n",
    "\n",
    "# Split the training+validation into training (75%) and validation (25%) to achieve 60% training, 20% validation of the total data\n",
    "features_train, features_val, target_train, target_val = train_test_split(\n",
    "    features_train_val, target_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of model 1: 0.1508\n",
      "The accuracy of model 1: 0.8501984126984127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Reinitialize and train the MLPClassifier on the training data\n",
    "model_1 = MLPClassifier(hidden_layer_sizes=(100), max_iter=500, activation='relu', solver='adam', random_state=42)\n",
    "model_1.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = model_1.predict(features_train)\n",
    "train_accuracy = accuracy_score(target_train, train_predictions)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "z1 = model_1.predict(features_val)\n",
    "err_rate_1 = (z1 != target_val).mean()  # Calculating the error rate\n",
    "\n",
    "print(f\"Error rate of model 1: {err_rate_1:.4f}\")\n",
    "print(f'The accuracy of model 1: {train_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize and train the MLPClassifier on the training data\n",
    "model_2 = MLPClassifier(hidden_layer_sizes=(100, 300), max_iter=500, activation='relu', solver='adam', random_state=42)\n",
    "model_2.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = model_2.predict(features_train)\n",
    "train_accuracy = accuracy_score(target_train, train_predictions)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "z2 = model_2.predict(features_val)\n",
    "err_rate_2 = (z2 != target_val).mean()  # Calculating the error rate\n",
    "\n",
    "print(f\"Error rate of model 2: {err_rate_2:.4f}\")\n",
    "print(f'The accuracy of model 2: {train_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of model 3: 0.1478\n",
      "The accuracy of model 3: 0.8858667087143909\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize and train the MLPClassifier with an additional layer\n",
    "model_3 = MLPClassifier(hidden_layer_sizes=(100, 300, 500), max_iter=500, activation='relu', solver='adam', random_state=42)\n",
    "model_3.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_predictions = model_3.predict(features_train)\n",
    "train_accuracy = accuracy_score(target_train, train_predictions)\n",
    "\n",
    "train_accuracy\n",
    "\n",
    "# Evaluate on the validation set\n",
    "z3 = model_3.predict(features_val)\n",
    "err_rate_3 = (z3 != target_val).mean()  # Calculating the error rate\n",
    "\n",
    "print(f\"Error rate of model 3: {err_rate_3:.4f}\")\n",
    "print(f'The accuracy of model 3: {train_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of model on test set: 0.1329\n",
      "Accuracy of model on test set: 0.8671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the testing set\n",
    "test_predictions = model_1.predict(features_test)\n",
    "\n",
    "# Calculate error rate and accuracy\n",
    "test_error_rate = (test_predictions != target_test).mean()  # Error rate\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)  # Accuracy\n",
    "\n",
    "print(f\"Error rate of model on test set: {test_error_rate:.4f}\")\n",
    "print(f\"Accuracy of model on test set: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of model on test set: 0.1465\n",
      "Accuracy of model on test set: 0.8535\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testing set\n",
    "test_predictions = model_2.predict(features_test)\n",
    "\n",
    "# Calculate error rate and accuracy\n",
    "test_error_rate = (test_predictions != target_test).mean()  # Error rate\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)  # Accuracy\n",
    "\n",
    "print(f\"Error rate of model on test set: {test_error_rate:.4f}\")\n",
    "print(f\"Accuracy of model on test set: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of model on test set: 0.1483\n",
      "Accuracy of model on test set: 0.8517\n"
     ]
    }
   ],
   "source": [
    "# Predict on the testing set\n",
    "test_predictions = model_3.predict(features_test)\n",
    "\n",
    "# Calculate error rate and accuracy\n",
    "test_error_rate = (test_predictions != target_test).mean()  # Error rate\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)  # Accuracy\n",
    "\n",
    "print(f\"Error rate of model on test set: {test_error_rate:.4f}\")\n",
    "print(f\"Accuracy of model on test set: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
